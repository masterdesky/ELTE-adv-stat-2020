{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from ipywidgets import *\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Central Limit Theorems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'classical' Central Limit Theorem states that if have IID variables where the variance of the marginal distribution is finite, then the sum of the variables is converging in distribution to a **Normal distribution**.\n",
    "\n",
    "Thus, if $X_1,X_2,\\dots,X_n$ are IID variables where $\\mathbb{E}(X_i)=\\mu$ and $\\mathbb{V}(X_i)=\\sigma^2$, then for $W_n=\\sum_{i=1}^n X_i$ we can write \n",
    "\\begin{equation}\n",
    "W_n \\overset{\\rm d}{\\longrightarrow} N(n\\mu,\\sqrt{n}\\sigma), \\nonumber\n",
    "\\end{equation}\n",
    "where we used the fact that both the sum and the variance can be simply summed for independent variables. As we can see, when $n\\rightarrow\\infty$, we obtain a Normal distribution with infinitely large mean and variance. \n",
    "\n",
    "The usual trick is to consider a **standardised** version of the sum of the variables, where we shift the variable such that the mean becomes 0 and rescale the variable such that the variance becomes 1. In this case this can be done simply by defining $Z_n$ as\n",
    "\\begin{equation}\n",
    "Z_n =\\frac{\\left(\\sum_{i=1}^n X_i\\right) -n\\mu}{\\sqrt{n}\\sigma}=\n",
    "\\frac{\\frac{1}{n}\\left(\\sum_{i=1}^n X_i\\right) - \\mu}{\\sigma/\\sqrt{n}} =\\frac{\\sqrt{n}\\left(\\overline{X_n}-\\mu\\right)}{\\sigma},\n",
    "\\end{equation}\n",
    "which is converging to standard Normal in distribution, \n",
    "\\begin{equation}\n",
    "Z_n\\overset{\\rm d}{\\longrightarrow}N(0,1).\n",
    "\\end{equation}\n",
    "\n",
    "Let's try this out. \n",
    "\n",
    "We are going to generate $n$ sample sets using numpy, and then add the data points from the different samples to \"simulate\" $Z_n$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define the parameters of our study, the number of data points in each sample, and the number of sample sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 20000;  # we are going to have this many random numbers in one given sample\n",
    "n = 50;              # and we generate this many different samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summing uniformly distributed variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probably the most simple case is when the individual $X_i$ variables are distributed uniformly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distr_list = [np.random.uniform(low=0,high=1,size= num_points) for i in range(0,n)];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function that can sum up to a specified number of variables, and return the distribution of the result. We also include the **standardisation** in the process, i.e., subtract the mean and divide by the standard deviation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sum_distr(distr_list,sum_size):\n",
    "    s_distr = [sum([distr_list[i][j] for i in range(0,sum_size)]) for j in range(0,len(distr_list[0]))];\n",
    "    s_mean,s_var = np.mean(s_distr),np.var(s_distr,ddof=1.0);\n",
    "    c_distr = [ (x-s_mean)/math.sqrt(s_var) for x in s_distr];\n",
    "    return c_distr;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply the above function to the generated list of sample lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_distr_list = [Sum_distr(distr_list,num_in_sum) for num_in_sum in range(1,n+1)];    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we plot the standardised distributions of the summed variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf();\n",
    "for s_distr in sum_distr_list[:2]:\n",
    "    hist,bins = np.histogram(s_distr,bins=50,normed=True); # Try: different bins, without normed\n",
    "    plt.plot(bins[:-1],hist,'o',alpha=0.2);\n",
    "    plt.ylim(0,1.0);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is instructive to see what happens when the standardisation is not carried out properly. **Try to mess up the standardisation and see what happens.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also make an interactive plot where the number of variables summed can be controlled by a slider.\n",
    "\n",
    "First we need to define a plotting function taking the number of summed variables as an argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot_sum_distr(s_distr_list,chosen_distr_id):\n",
    "    hist,bins = np.histogram(s_distr_list[chosen_distr_id-1],bins=50,normed=True);\n",
    "    plt.plot(bins[:-1],hist);\n",
    "    x_list = np.arange(-4,4,0.1);\n",
    "    y_list = [math.exp(-0.5*x**2)/math.sqrt(2.0*np.pi) for x in x_list];\n",
    "    plt.plot(x_list,y_list);\n",
    "    plt.xlabel(r'$\\frac{x-\\overline{X}}{\\rm sd}$')\n",
    "    plt.ylim(0,1.0);\n",
    "    plt.xlim(-4,4);\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we can turn this into an interactive window with a slider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(Plot_sum_distr,s_distr_list=fixed(sum_distr_list),\n",
    "         chosen_distr_id = IntSlider(min=1,max=n,step=1,value=1,description='num. distr. summed'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's repeat the above for e.g., exponentially distributed variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_distr_list = [np.random.exponential(3.0,num_points) for i in range(0,n)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_exp_distr = [Sum_distr(exp_distr_list,num_in_sum) for num_in_sum in range(1,n+1)];    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(Plot_sum_distr,s_distr_list=fixed(sum_exp_distr),\n",
    "         chosen_distr_id = IntSlider(min=1,max=n,step=1,value=1,description='num. distr. summed'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summing heavy tailed distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The central limit theorem for heavy tailed distributions with diverging variance is different. Let's have a look at that too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pareto_a = 1.5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pareto_distr_list = [np.random.pareto(pareto_a,num_points) for i in range(0,n)];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key difference is that if the PDF of the marginal is decaying as $x^{-\\alpha}$ (where $2<\\alpha<3$), then we have to 'standardise' the sum by dividing with $n^{1/\\mu}$, where $\\mu=\\alpha-1$.\n",
    "\n",
    "Thus, the summing function in this case has to take an argument corresponding to $\\mu$ as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sum_Pareto(distr_list,sum_size,mu):\n",
    "    s_distr = [sum([distr_list[i][j] for i in range(0,sum_size)]) for j in range(0,len(distr_list[0]))];\n",
    "    s_mean = np.mean(s_distr);\n",
    "    c_distr = [ (x-s_mean)/sum_size**(1.0/mu) for x in s_distr];\n",
    "    return c_distr;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try this out when we set $\\mu$ correctly and also when we set it wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 1.0;\n",
    "sum_par_distr = [Sum_Pareto(pareto_distr_list,n,mu) for n in range(1,n+1)];   \n",
    "plt.clf();\n",
    "for s_distr in sum_par_distr:\n",
    "    hist,bins = np.histogram(s_distr,bins=np.logspace(0,3,50),density=True);\n",
    "    plt.loglog(bins[:-1],hist,'o',alpha = 0.2);\n",
    "    plt.title(r'$\\alpha$='+str(pareto_a+1)+', $\\mu$='+str(mu));\n",
    "plt.show();\n",
    "\n",
    "mu = 1.5;\n",
    "sum_par_distr = [Sum_Pareto(pareto_distr_list,n,mu) for n in range(1,n+1)];   \n",
    "plt.clf();\n",
    "for s_distr in sum_par_distr:\n",
    "    hist,bins = np.histogram(s_distr,bins=np.logspace(0,3,50),density=True);\n",
    "    plt.loglog(bins[:-1],hist,'o',alpha = 0.2);\n",
    "    plt.title(r'$\\alpha$='+str(pareto_a+1)+', $\\mu$='+str(mu));\n",
    "plt.show();\n",
    "\n",
    "mu = 2.0;\n",
    "sum_par_distr = [Sum_Pareto(pareto_distr_list,n,mu) for n in range(1,n+1)];   \n",
    "plt.clf();\n",
    "for s_distr in sum_par_distr:\n",
    "    hist,bins = np.histogram(s_distr,bins=np.logspace(0,3,50),density=True);\n",
    "    plt.loglog(bins[:-1],hist,'o',alpha = 0.2);\n",
    "    plt.title(r'$\\alpha$='+str(pareto_a+1)+', $\\mu$='+str(mu));\n",
    "plt.show();\n",
    "\n",
    "mu = 2.5;\n",
    "sum_par_distr = [Sum_Pareto(pareto_distr_list,n,mu) for n in range(1,n+1)];   \n",
    "plt.clf();\n",
    "for s_distr in sum_par_distr:\n",
    "    hist,bins = np.histogram(s_distr,bins=np.logspace(0,3,50),density=True);\n",
    "    plt.loglog(bins[:-1],hist,'o',alpha = 0.2);\n",
    "    plt.title(r'$\\alpha$='+str(pareto_a+1)+', $\\mu$='+str(mu));\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we can also make an interactive plot with a slider in a similar fashion to the normal Central Limit Theorem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot_sum_Pareto(sum_distr_list,chosen_distr_id):\n",
    "    hist,bins = np.histogram(sum_distr_list[chosen_distr_id-1],bins=np.logspace(0,3,50),normed=True);\n",
    "    plt.loglog(bins[:-1],hist);\n",
    "    plt.xlim(1,1000);\n",
    "    plt.ylim(0.0001,1);\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(Plot_sum_Pareto,sum_distr_list=fixed(sum_par_distr),\n",
    "         chosen_distr_id = IntSlider(min=1,max=n,step=1,value=1,description='num. distr. summed'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock market simulation II."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returning to the simulation of stock values: What happens if the value is changed by **multiplying** with a random variable $x$ instead of adding? \n",
    "\n",
    "In this setting, probably the simplest scenario is when $P(x=r)=1/2$ and $P(x=1/r)=1/2$. Let's try it out!\n",
    "\n",
    "First we specify the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_fact = 1.05;        # this is what we denoted as \"r\" in the above.\n",
    "num_stocks = 5;            # number of stocks\n",
    "num_time_steps = 10000;    # length of the time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the builf in function reduce() to subsequently multiply the elements from a previously generated random sequence of $r$ and $1/r$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_time_series_list = [];\n",
    "stock_time_series_list.clear();\n",
    "for i in range(0,num_stocks):\n",
    "    rand_changes = list(np.random.choice([change_fact,1.0/change_fact],num_time_steps)); # these are the random \n",
    "                                                                                         # r and 1/r factors.\n",
    "    stock_value = [reduce((lambda x,y: x*y),rand_changes[0:n]) for n in range(1,len(rand_changes))];\n",
    "    stock_time_series_list.append(stock_value);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ** Try to make a plot of the obtained stock value series as before **\n",
    "- ** What is different compared to the more simple additive simulation? **\n",
    "- ** What is the distribution of the stock values after a sufficient number of time steps? **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf();\n",
    "t_list = range(0,len(stock_time_series_list[0]));\n",
    "for i in range(0,len(stock_time_series_list)):\n",
    "    plt.semilogy(t_list,stock_time_series_list[i],label = 'stock no.'+str(i));\n",
    "plt.xlabel('time steps');\n",
    "plt.ylabel('stock value');\n",
    "plt.xlim(0,1000);\n",
    "plt.ylim(0.1,8);\n",
    "plt.legend(loc= 'upper left',fontsize = 10);\n",
    "plt.show();\n",
    "\n",
    "plt.clf();\n",
    "fig,ax = plt.subplots();\n",
    "for i in range(0,len(stock_time_series_list)):\n",
    "    plt.semilogy(t_list,stock_time_series_list[i],label = 'stock no.'+str(i));\n",
    "plt.xlabel('time steps');\n",
    "plt.ylabel('stock value');\n",
    "#plt.ylim(-300,300);\n",
    "#rect = patches.Rectangle((0,-95),1000,190,edgecolor='r',facecolor='r', alpha = 0.1);\n",
    "#ax.add_patch(rect);\n",
    "plt.legend(loc= 'upper left',fontsize = 10);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "widgets": {
   "state": {
    "399aafb534744f0f9f411c9b12edb9ef": {
     "views": [
      {
       "cell_index": 33
      }
     ]
    },
    "44981d9adac64d1fbd6780c01965c178": {
     "views": [
      {
       "cell_index": 22
      }
     ]
    },
    "d213a72bc55f4a9d9b56f952932287f6": {
     "views": [
      {
       "cell_index": 18
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
