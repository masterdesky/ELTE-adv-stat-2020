{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = '.\\\\out\\\\'\n",
    "figsave_format = 'pdf'\n",
    "figsave_dpi = 200\n",
    "\n",
    "# Set axtick dimensions\n",
    "major_size = 6\n",
    "major_width = 1.2\n",
    "minor_size = 3\n",
    "minor_width = 1\n",
    "mpl.rcParams['xtick.major.size'] = major_size\n",
    "mpl.rcParams['xtick.major.width'] = major_width\n",
    "mpl.rcParams['xtick.minor.size'] = minor_size\n",
    "mpl.rcParams['xtick.minor.width'] = minor_width\n",
    "mpl.rcParams['ytick.major.size'] = major_size\n",
    "mpl.rcParams['ytick.major.width'] = major_width\n",
    "mpl.rcParams['ytick.minor.size'] = minor_size\n",
    "mpl.rcParams['ytick.minor.width'] = minor_width\n",
    "\n",
    "# Seaborn style settings\n",
    "sns.set_style({'axes.axisbelow': True,\n",
    "               'axes.edgecolor': '.8',\n",
    "               'axes.facecolor': 'white',\n",
    "               'axes.grid': True,\n",
    "               'axes.labelcolor': '.15',\n",
    "               'axes.spines.bottom': True,\n",
    "               'axes.spines.left': True,\n",
    "               'axes.spines.right': True,\n",
    "               'axes.spines.top': True,\n",
    "               'figure.facecolor': 'white',\n",
    "               'font.family': ['sans-serif'],\n",
    "               'font.sans-serif': ['Arial',\n",
    "                'DejaVu Sans',\n",
    "                'Liberation Sans',\n",
    "                'Bitstream Vera Sans',\n",
    "                'sans-serif'],\n",
    "               'grid.color': '.8',\n",
    "               'grid.linestyle': '--',\n",
    "               'image.cmap': 'rocket',\n",
    "               'lines.solid_capstyle': 'round',\n",
    "               'patch.edgecolor': 'w',\n",
    "               'patch.force_edgecolor': True,\n",
    "               'text.color': '.15',\n",
    "               'xtick.bottom': True,\n",
    "               'xtick.color': '.15',\n",
    "               'xtick.direction': 'in',\n",
    "               'xtick.top': True,\n",
    "               'ytick.color': '.15',\n",
    "               'ytick.direction': 'in',\n",
    "               'ytick.left': True,\n",
    "               'ytick.right': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random variables and distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A general random number generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose $X$ has a CDF $F(x)$, which means that $F(x): \\mathbb{R}\\rightarrow [0,1]$, and let us assume that $F(x)$ is invertible. Based on that,  ** we can generate random numbers simulating draws from $F$ ** as follows:\n",
    " - We generate random numbers with uniform distribution in the $[0,1]$ interval, i.e., $Y\\sim$Uni(0,1), and $y_i$ are drawn from $Y$,\n",
    " - We define $X=F^{-1}(Y)$, thus, $x_i = F^{-1}(y_i)$. \n",
    "\n",
    "Too prove that this actually works, let us consider the probability that $X<z\\in \\mathbb{R}$. This can be given as\n",
    "\\begin{equation}\n",
    "P(X<z)=P\\left(F(X)<F(z)\\right)=P\\left(F[F^{-1}(Y)]< F(z)\\right)=P(Y<F(z)). \\nonumber\n",
    "\\end{equation}\n",
    "Since $Y$ has a uniform distribution over the $[0,1]$ interval, the probability that $Y<y$ is simply $P(Y<y)=y$, thus, \n",
    "\\begin{equation}\n",
    "P(X<z)=P(Y<F(z))=F(z), \\nonumber\n",
    "\\end{equation}\n",
    "which means that the CDF of $X$ is actually $F(z)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Illustration with exponentially distributed random numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us test this in case of the Exponential distribution, where the CDF is $F(x)=1-e^{-\\frac{x}{\\lambda}}$. The inverse can be expressed as $F^{-1}(y)=-\\lambda\\ln(1-y)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define a function which generates uniform random numbers in the $[0,1]$ interval using the built in random generator of numpy, and then transforms these according to $F^{-1}$, returning a list of exponentially distributed random numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gen_exp_rand(lam_value,num_rands):\n",
    "    rand_list = np.random.random(num_rands)\n",
    "    return [-lam_value*math.log(1.0-y) for y in rand_list]\n",
    "    #return list(map(lambda y: -lam_value*math.log(1-y),rand_list))\n",
    "    #return np.array([ -lam_value*math.log(1.0-y) for y in rand_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the parameter of the distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_lambda = 3.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we generate a list of say, 1000 random numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try_list = Gen_exp_rand(exp_lambda,5000)\n",
    "#print(try_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the result using the histogram plot of pyplot. To check whether they really follow the exponential distribution, we plot aside the PDF of the exponential distribution as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 1\n",
    "ncols = 2\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(ncols*10, nrows*7))\n",
    "\n",
    "axislabelsize = 18\n",
    "axisticksize = 15\n",
    "\n",
    "bins = [50, 100]\n",
    "colors = [\n",
    "    'tab:blue',\n",
    "    'tab:green'\n",
    "]\n",
    "\n",
    "for i in range(ncols):\n",
    "    # pyplot can automatically gather the data into bins, and also normalise it\n",
    "    axes[i].hist(try_list, bins[i], density=True,\n",
    "                 color=colors[i], label='binned data')\n",
    "\n",
    "    # Let us also plot the theoretical PDF\n",
    "    x_vec = np.arange(0, 5*exp_lambda, 0.1)\n",
    "    y = np.exp(-x_vec/exp_lambda) / exp_lambda\n",
    "    axes[i].plot(x_vec, y,\n",
    "                 c='tab:orange', label='theor. PDF')\n",
    "    axes[i].set_xlabel('$x$', fontsize=axislabelsize)\n",
    "    axes[i].set_ylabel('PDF', fontsize=axislabelsize)\n",
    "    axes[i].tick_params(axis='both', which='major', labelsize=axisticksize)\n",
    "\n",
    "    axes[i].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating random samples with numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, for a simple distribution like the Exponential distribution, numpy provides a direct solution, and we do not have to use the inversion trick. In fact, numpy can generate random numbers according to quite a few distributions. Let us try out a couple of these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu,sigma,num_points = 20,1.55,50000\n",
    "normal_data = np.random.normal(mu,sigma,num_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 1\n",
    "ncols = 2\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(ncols*10, nrows*7))\n",
    "\n",
    "axislabelsize = 18\n",
    "axisticksize = 15\n",
    "\n",
    "bins = [50, 100]\n",
    "colors = [\n",
    "    'tab:blue',\n",
    "    'tab:green'\n",
    "]\n",
    "\n",
    "for i in range(ncols):\n",
    "    # pyplot can automatically gather the data into bins, and also normalise it\n",
    "    axes[i].hist(normal_data, bins[i], density=True,\n",
    "                 color=colors[i], label='binned data')\n",
    "\n",
    "    # Let us also plot the theoretical PDF\n",
    "    x_vec = np.arange(mu - 5*sigma, mu + 5*sigma, 0.2)\n",
    "    y = np.exp(-(x_vec - mu)**2 / (2 * sigma**2)) / (np.sqrt(2*np.pi)*sigma)\n",
    "    axes[i].plot(x_vec, y,\n",
    "                 c='tab:orange', label='theor. PDF')\n",
    "    axes[i].set_xlabel('$x$', fontsize=axislabelsize)\n",
    "    axes[i].set_ylabel('PDF', fontsize=axislabelsize)\n",
    "    axes[i].tick_params(axis='both', which='major', labelsize=axisticksize)\n",
    "\n",
    "    axes[i].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gamma distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_q, gamma_lambda, num_points = 20,7.2,50000;\n",
    "gamma_data = np.random.gamma(gamma_q,gamma_lambda,num_points);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 1\n",
    "ncols = 2\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(ncols*10, nrows*7))\n",
    "\n",
    "axislabelsize = 18\n",
    "axisticksize = 15\n",
    "\n",
    "bins = [50, 100]\n",
    "colors = [\n",
    "    'tab:blue',\n",
    "    'tab:green'\n",
    "]\n",
    "\n",
    "for i in range(ncols):\n",
    "    # pyplot can automatically gather the data into bins, and also normalise it\n",
    "    axes[i].hist(gamma_data, bins[i], density=True,\n",
    "                 color=colors[i], label='binned data')\n",
    "\n",
    "    axes[i].set_xlim(0,300)\n",
    "    \n",
    "    # Let us also plot the theoretical PDF\n",
    "    x_vec = np.arange(0.1, gamma_q * gamma_lambda * (1 + gamma_lambda), 0.2)\n",
    "    y = x_vec**(gamma_q - 1) * np.exp(-x_vec/gamma_lambda) / (gamma_lambda**gamma_q * math.gamma(gamma_q))\n",
    "    axes[i].plot(x_vec, y,\n",
    "                 c='tab:orange', label='theor. PDF')\n",
    "    axes[i].set_xlabel('$x$', fontsize=axislabelsize)\n",
    "    axes[i].set_ylabel('PDF', fontsize=axislabelsize)\n",
    "    axes[i].tick_params(axis='both', which='major', labelsize=axisticksize)\n",
    "\n",
    "    axes[i].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\chi^2$ distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_q = 7\n",
    "num_points = 50000\n",
    "\n",
    "chi_sq_data = np.random.chisquare(chi_q,num_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 1\n",
    "ncols = 2\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(ncols*10, nrows*7))\n",
    "\n",
    "axislabelsize = 18\n",
    "axisticksize = 15\n",
    "\n",
    "bins = [50, 100]\n",
    "colors = [\n",
    "    'tab:blue',\n",
    "    'tab:green'\n",
    "]\n",
    "\n",
    "for i in range(ncols):\n",
    "    # pyplot can automatically gather the data into bins, and also normalise it\n",
    "    axes[i].hist(chi_sq_data, bins[i], density=True,\n",
    "                 color=colors[i], label='binned data')\n",
    "    \n",
    "    # Let us also plot the theoretical PDF\n",
    "    x_vec = np.arange(0, chi_q*3, 0.2)\n",
    "    y = x_vec**(chi_q/2 - 1) * np.exp(-x_vec/2) / 2**(chi_q/2) / math.gamma(chi_q/2)\n",
    "    axes[i].plot(x_vec, y,\n",
    "                 c='tab:orange', label='theor. PDF')\n",
    "    axes[i].set_xlabel('$x$', fontsize=axislabelsize)\n",
    "    axes[i].set_ylabel('PDF', fontsize=axislabelsize)\n",
    "    axes[i].tick_params(axis='both', which='major', labelsize=axisticksize)\n",
    "\n",
    "    axes[i].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cauchy distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 50000\n",
    "cauchy_data = np.random.standard_cauchy(num_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 1\n",
    "ncols = 2\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(ncols*10, nrows*7))\n",
    "\n",
    "axislabelsize = 18\n",
    "axisticksize = 15\n",
    "\n",
    "bins = [50, 100]\n",
    "colors = [\n",
    "    'tab:blue',\n",
    "    'tab:green'\n",
    "]\n",
    "\n",
    "for i in range(ncols):\n",
    "    # pyplot can automatically gather the data into bins, and also normalise it\n",
    "    axes[i].hist(cauchy_data, bins[i], range=(-20,20), density=True,\n",
    "                 color=colors[i], label='binned data')\n",
    "    axes[i].set_xlim(-20,20)\n",
    "    \n",
    "    # Let us also plot the theoretical PDF\n",
    "    x_vec = np.arange(-20,20,0.2)\n",
    "    y = (1 / np.pi) * (1 / (1 + x_vec**2))\n",
    "    axes[i].plot(x_vec, y,\n",
    "                 c='tab:orange', label='theor. PDF')\n",
    "    axes[i].set_xlabel('$x$', fontsize=axislabelsize)\n",
    "    axes[i].set_ylabel('PDF', fontsize=axislabelsize)\n",
    "    axes[i].tick_params(axis='both', which='major', labelsize=axisticksize)\n",
    "\n",
    "    axes[i].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pareto distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A heavy tailed distribution where we can actualy change the shape of the distribution with the help of parameters is given by the ** Pareto distribution** , having a PDF written as\n",
    "\\begin{equation}\n",
    "\\rho(x) =  a \\frac{x_m^a}{x^{a+1}}, \\nonumber\n",
    "\\end{equation}\n",
    "where $x$ is assumed to be $x\\geq x_m$.\n",
    "\n",
    "A closely related distribution is the **Lomax distribution**, which is essentially a Pareto distribution shifted such that its support is $[0,\\infty]$ instead of $[m,\\infty]$. The PDF of the Lomax distribution is given by\n",
    "\\begin{equation}\n",
    "\\rho(x) = \\frac{a}{m}\\left[1+\\frac{x}{m}\\right]^{-(a+1)}. \\nonumber\n",
    "\\end{equation}\n",
    "\n",
    "Numpy has a function numpy.random.pareto(), which generates random numbers drawn from the Lomax distribution. Let's try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1.5\n",
    "pareto_data = np.random.pareto(a, num_points) # the m parameter is 1 by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 1\n",
    "ncols = 2\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(ncols*10, nrows*7))\n",
    "\n",
    "axislabelsize = 18\n",
    "axisticksize = 15\n",
    "\n",
    "bins = [50, 100]\n",
    "colors = [\n",
    "    'tab:blue',\n",
    "    'tab:green'\n",
    "]\n",
    "\n",
    "for i in range(ncols):\n",
    "    # pyplot can automatically gather the data into bins, and also normalise it\n",
    "    axes[i].hist(pareto_data, bins[i], range=(0,10), density=True,\n",
    "                 color=colors[i], label='binned data')\n",
    "    axes[i].set_xlim(0,10)\n",
    "    \n",
    "    # Let us also plot the theoretical PDF\n",
    "    x_vec = np.arange(0,10,0.2) \n",
    "    y = a * (1 + x_vec)**(-1 - a)\n",
    "    axes[i].plot(x_vec, y,\n",
    "                 c='tab:orange', label='theor. PDF')\n",
    "    axes[i].set_xlabel('$x$', fontsize=axislabelsize)\n",
    "    axes[i].set_ylabel('PDF', fontsize=axislabelsize)\n",
    "    axes[i].tick_params(axis='both', which='major', labelsize=axisticksize)\n",
    "\n",
    "    axes[i].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to obtain random sample drawn really from Pareto distribution and not Lomax? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logarithmic binning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When dealing with a heavy tailed distribution, it is usually worthy to plot it also on log-log scale, because the tail of the distribution becomes much more visible. \n",
    "\n",
    "However, in order to plot data on logarithmic scale, it would be nice to apply logarithmic binning, where the size of the bins looks even on log-scale (which means that their size is increasing exponentially). Luckily, numpy has a logspace function which can be used for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf();\n",
    "hist,bins = np.histogram(pareto_data,bins=np.logspace(-1,3,50),density=True);\n",
    "plt.loglog(bins[:-1],hist,'bo', label='Lomax sample binned');\n",
    "y=[a*(1.0+x)**(-1.0-a) for x in bins[:-1]];\n",
    "plt.plot(bins[:-1],y,label ='Lomax PDF');\n",
    "plt.legend();\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logarithmic plot is also better when we have doubts whether two distributions decay with the same exponent or not. \n",
    "\n",
    "To illustrate this, let us generate data drawn from Lomax distribution with a different exponent, and plot the two PDF first on linear scale, then on logarithmic scale. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 2.0;\n",
    "pareto_alt = np.random.pareto(b,num_points);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the linear plot with fixed $x$ range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf();\n",
    "hist_a,bins_a = np.histogram(pareto_data,bins= np.arange(0,50,0.2),density=True);\n",
    "plt.plot(bins_a[:-1],hist_a,'bo', label='Lomax, a='+str(a));\n",
    "\n",
    "hist_b,bins_b = np.histogram(pareto_alt,bins=np.arange(0,50,0.2), density = True);\n",
    "plt.plot(bins_b[:-1],hist_b,'go', label = 'Lomax, a='+str(b));\n",
    "\n",
    "y_a=[a*(1.0+x)**(-1.0-a) for x in bins_a[:-1]];\n",
    "y_b=[b*(1.0+x)**(-1.0-b) for x in bins_b[:-1]];\n",
    "plt.plot(bins_a[:-1],y_a);\n",
    "plt.plot(bins_b[:-1],y_b);\n",
    "plt.legend();\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, the same on logarithmic scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf();\n",
    "hist_a,bins_a = np.histogram(pareto_data,bins=np.logspace(-1,3,50),density=True);\n",
    "plt.loglog(bins_a[:-1],hist_a,'bo', label='Lomax, a='+str(a));\n",
    "\n",
    "hist_b,bins_b = np.histogram(pareto_alt,bins=np.logspace(-1,3,50), density = True);\n",
    "plt.loglog(bins_b[:-1],hist_b,'go', label = 'Lomax, a='+str(b));\n",
    "\n",
    "y_a=[a*(1.0+x)**(-1.0-a) for x in bins_a[:-1]];\n",
    "y_b=[b*(1.0+x)**(-1.0-b) for x in bins_b[:-1]];\n",
    "plt.plot(bins_a[:-1],y_a);\n",
    "plt.plot(bins_b[:-1],y_b);\n",
    "plt.legend();\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
