{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Free time series data at provider pages\n",
    "\n",
    "1. Based on the descriptions at the provider pages, explain what each data set means.\n",
    "\n",
    "2. Select two data sets and compare their changes when something happens in the world.\n",
    "\n",
    "| Source | Name, Link to page | Type | Further information |\n",
    "| :--- | :--| :--- | :-- |\n",
    "| [Yahoo Finance](https://finance.yahoo.com) | [Walmart stock price](https://finance.yahoo.com/quote/WMT/history) | Equity | Retail, Big capitalization |\n",
    "| &nbsp; | [Amazon](https://finance.yahoo.com/quote/AMZN/history) | &nbsp; | IT, Big cap |\n",
    "| &nbsp; | [Tesla](https://finance.yahoo.com/quote/TSLA/history) | &nbsp; | New technology |\n",
    "| &nbsp; | [BJ's Restaurants](https://finance.yahoo.com/quote/BJRI/history) | &nbsp; | Catering industry, Small cap |\n",
    "| &nbsp; | [Bitcoin](https://finance.yahoo.com/quote/BTC-USD/history) | Crypto |  Meant for payments | \n",
    "| &nbsp; | [Ethereum](https://finance.yahoo.com/quote/ETH-USD/history) | &nbsp; | More infrastructural | \n",
    "| [FRED](https://fred.stlouisfed.org) | Employment: [Not seasonally adjusted](https://fred.stlouisfed.org/series/PAYNSA)<br/>and [Seasonally adjusted](https://fred.stlouisfed.org/series/PAYEMS) | Macroeconomy | Total non-farm employees |\n",
    "| &nbsp; | [S&P500 stock market index](https://fred.stlouisfed.org/series/SP500) | Equity index |  Large cap stocks |\n",
    "| &nbsp; | [USD 2Y swap rate ICE](https://fred.stlouisfed.org/series/ICERATES1100USD2Y) | Rate | [ICE methodology](https://www.theice.com/publicdocs/ICE_Swap_Rate_Full_Calculation_Methodology.pdf) |\n",
    "| &nbsp; | [Ounce of gold in USD](https://fred.stlouisfed.org/series/GOLDAMGBD228NLBM) | Commodity | Gold: bullion |\n",
    "| &nbsp; | [Moody's AAA 10Y credit spread](https://fred.stlouisfed.org/series/AAA10Y) | Credit | Spread to 10Y T-bond |\n",
    "| &nbsp; | [YEN / USD exchange rate](https://fred.stlouisfed.org/series/DEXJPUS) | FX | FX: Foreign Exchange | \n",
    "| &nbsp; | [Wilshire US Real Estate Securities Price Index](https://www.wilshire.com/indexes/wilshire-real-estate-family/wilshire-us-resi)  | Real estate index | [Wilshire's description](https://www.wilshire.com/indexes/wilshire-real-estate-family/wilshire-us-resi) |\n",
    "| [ECB](https://sdw.ecb.europa.eu) | [USD / EUR exchange rate](https://sdw.ecb.europa.eu/quickview.do?SERIES_KEY=120.EXR.D.USD.EUR.SP00.A) | FX | ECB reference rate |\n",
    "| [Portfolio.hu](https://www.portfolio.hu/adatletoltes) | OTP | Equity | Banking, Regional |\n",
    "| &nbsp; | Richter | &nbsp; | Pharma |\n",
    "| &nbsp; | BUX | Equity Index | Budapest Stock Exch |\n",
    "| &nbsp; | EUR / HUF | FX | Hu Natl Bank |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate the data locally\n",
    "\n",
    "1. For Yahoo and FRED data sets, explain the meaning of each column.\n",
    "2. For each Yahoo data set calculate the median / maximum ratio of the daily Volume shown in the last column. Which data set has the lowest ratio ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# open/close code\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# modules, variables\n",
    "import pandas as pd\n",
    "import os\n",
    "data_dir = \"data\"\n",
    "file_ext = \"csv\"\n",
    "df = dict() # data frames by key (data set code)\n",
    "\n",
    "# Time series from: Yahoo Finance, Federal Reserve Economic Data, European Central Bank, Portfolio.hu\n",
    "yahooCodes = ['WMT','AMZN','TSLA','BJRI','BTC-USD','ETH-USD']\n",
    "fred_codes = ['PAYEMS','PAYNSA','AAA10Y','DEXJPUS','GOLDPMGBD228NLBM','ICERATES1100USD1Y','SP500','WILLRESIPR']\n",
    "ecb_codes = ['EXR.D.USD.EUR.SP00.A']\n",
    "pf_codes = ['BUX','OTP','RICHTER']\n",
    "all_codes = yahooCodes + fred_codes + ecb_codes + pf_codes\n",
    "\n",
    "# Investigate each data frame\n",
    "for code in all_codes:\n",
    "    df[code] = pd.read_csv(data_dir + os.sep + code + \".\" + file_ext)\n",
    "    print(os.linesep+\"> \"+code)\n",
    "    print(df[code].head())\n",
    "    print(df[code].tail())\n",
    "    print(df[code].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot value. Plot Daily and Monthly log return.\n",
    "\n",
    "1. Noting that the vertical scale is logarithmic, which stocks have had long periods of exponential growth ?\n",
    "2. In which year did WMT (Walmart) have bigger changes relative to itself: 1975 or 2005 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# open/close code\n",
    "# modules, variables\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "def last_date_in_each_month(businessDays):\n",
    "    '''Get last date in each month of a time series'''\n",
    "    dateRange = []  \n",
    "    tempYear = None  \n",
    "    dictYears = businessDays.groupby(businessDays.year)\n",
    "    for yr in dictYears.keys():\n",
    "        tempYear = pd.DatetimeIndex(dictYears[yr]).groupby(pd.DatetimeIndex(dictYears[yr]).month)\n",
    "        for m in tempYear.keys():\n",
    "            dateRange.append(max(tempYear[m]))\n",
    "    return dateRange\n",
    "\n",
    "# set dataframe index to datetime\n",
    "for code in yahooCodes:\n",
    "    df[code].index = pd.to_datetime( df[code]['Date'] )\n",
    "\n",
    "# create dataframe of monthly returns\n",
    "dfm = dict() # dict to save monthly close data by data set key\n",
    "for code in yahooCodes:    \n",
    "    all_dates = df[code].index\n",
    "    month_last_dates = last_date_in_each_month(all_dates)\n",
    "    dfm[code] = pd.DataFrame(df[code], index=month_last_dates)\n",
    "\n",
    "# daily and monthly log return\n",
    "for code in yahooCodes:\n",
    "    df[code]['LogReturn']  = np.log(df[code]['Close']) -  np.log(df[code]['Close'].shift())\n",
    "    dfm[code]['LogReturn'] = np.log(dfm[code]['Close']) - np.log(dfm[code]['Close'].shift())\n",
    "\n",
    "# parameters for drawing\n",
    "xlims=[datetime.date(1971,12,31),datetime.date(2020,6,30)] # horizontal axis limits\n",
    "ylims=[-.45,.45]\n",
    "removeOutlierBelowMinusOne = True # whether we should remove the log daily return outlier\n",
    "yahooColors = ['black','blue','#a0a0ff','salmon','limegreen','darkgreen']\n",
    "fontsize=12\n",
    "marker='.'\n",
    "\n",
    "# plot daily values\n",
    "plt.subplot(311)\n",
    "for code,color in zip(yahooCodes,yahooColors):\n",
    "    plt.plot(df[code]['Close'], c=color, marker=marker, label=code, lw=0)\n",
    "plt.legend(bbox_to_anchor=(0.01, .98), loc=2, borderaxespad=0., fontsize=fontsize)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Time [year]',fontsize=fontsize)\n",
    "plt.ylabel('Value of 1 Unit on log scale',fontsize=fontsize)\n",
    "plt.xlim(xlims)\n",
    "\n",
    "# plot logarithmic daily returns\n",
    "plt.subplot(312)\n",
    "for code,color in zip(yahooCodes,yahooColors):\n",
    "    s = df[code]['LogReturn']\n",
    "    if removeOutlierBelowMinusOne:\n",
    "        s = s[s>-1]\n",
    "    plt.plot(s, c=color, marker='.', ms=1, label=code, lw=0)\n",
    "plt.yscale('linear')\n",
    "plt.xlabel('Time [year]', fontsize=fontsize)\n",
    "plt.ylabel('Business Day Log Return', fontsize=fontsize)\n",
    "plt.xlim(xlims)\n",
    "#plt.ylim(ylims)\n",
    "\n",
    "# plot logarithmic monthly returns\n",
    "plt.subplot(313)\n",
    "normalization_factor = 1.0 # / np.sqrt(number_of_business_days_per_month)\n",
    "number_of_business_days_per_month = 21\n",
    "for code,color in zip(yahooCodes,yahooColors):\n",
    "    s = dfm[code]['LogReturn']\n",
    "    plt.plot(s * normalization_factor, c=color, marker='.', ms=2, label=code, lw=0)\n",
    "plt.yscale('linear')\n",
    "plt.xlabel('Time [year]', fontsize=fontsize)\n",
    "#plt.ylabel('Log Monthly Return / ' + r'$\\sqrt{' + str(number_of_business_days_per_month) + r'}$', fontsize=fontsize)\n",
    "plt.ylabel('Log Monthly Return', fontsize=fontsize)\n",
    "plt.xlim(xlims)\n",
    "#plt.ylim(ylims)\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches([16, 15])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log return distribution vs Normal\n",
    "1. On which time scale is BTC closer to normal: daily log returns or monthly log returns ?\n",
    "2. Can you find any data errors, for example, cutoff around zero ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# open/close code\n",
    "# selected data set for plotting\n",
    "selectedCode = 'BTC-USD'\n",
    "\n",
    "# import modules\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.special import erf\n",
    "# from scipy.stats import norm # only for norm.ppf\n",
    "import pandas as pd\n",
    "# select color for the data set\n",
    "code2num = { yahooCodes[num]:num for num in np.arange(len(yahooColors)) }\n",
    "selectedColor = yahooColors[code2num[selectedCode]]\n",
    "fontsize=12\n",
    "\n",
    "# helper functions\n",
    "def cdf(series):\n",
    "    '''Calculate CDF (cumulated density function)'''\n",
    "    series_dropna = series.dropna()\n",
    "    series_dropna_sorted = np.sort(series_dropna)\n",
    "    n = series_dropna.size\n",
    "    values = np.arange(1, n+1) / n\n",
    "    return(series_dropna_sorted, values)\n",
    "\n",
    "def func_normal_cdf(x, mu, sigma): \n",
    "    '''CDF of normal distribution with parameters mu,sigma'''\n",
    "    return 0.5 * ( 1.0 + erf((x-mu)/(sigma*np.sqrt(2.0))) ) \n",
    "\n",
    "# plot DAILY and MONTHLY\n",
    "for which_period in ([\"DAILY\", \"MONTHLY\"]):\n",
    "    dfsel = dict()\n",
    "    if which_period == \"DAILY\":\n",
    "        for key in df:\n",
    "            dfsel[key] = df[key].copy()\n",
    "    else:\n",
    "        for key in dfm:\n",
    "            dfsel[key] = dfm[key].copy()\n",
    "            \n",
    "    # Left: one selected time series as an example\n",
    "    cdfx, cdfy = cdf(dfsel[selectedCode]['LogReturn']) # CDF of daily log returns\n",
    "    popt, pcov = curve_fit(func_normal_cdf, cdfx, cdfy) # fit normal's CDF to observed CDF\n",
    "    cdfy_fit = func_normal_cdf(cdfx, *popt) # CDF fit points\n",
    "    plt.subplot(121)\n",
    "    plt.xlabel(which_period + \" log return\", fontsize=fontsize)\n",
    "    plt.ylabel(\"Cumulated density function  (CDF)\", fontsize=fontsize)\n",
    "    plt.title(selectedCode + \" : Observed CDF and Normal Fit CDF\", fontsize=fontsize)\n",
    "    plt.plot(cdfx, cdfy, c=selectedColor, marker='o', label=selectedCode, markersize=1, lw=1)\n",
    "    plt.plot(cdfx, cdfy_fit, c='k', ls=':', label='Normal fit',lw=1)\n",
    "    plt.legend(bbox_to_anchor=(.02, .93), loc=2, borderaxespad=0., fontsize=fontsize)\n",
    "    plt.axhline(0, c='k', ls=':', lw=.3)\n",
    "    plt.axhline(1, c='k', ls=':', lw=.3)\n",
    "    plt.axvline(0, c='k', ls=':', lw=.3)\n",
    "\n",
    "    # Right panel: Plot only selected or Plot all\n",
    "    plt.subplot(122)\n",
    "    for code,color in zip(yahooCodes,yahooColors):\n",
    "        #if True:\n",
    "        if code == selectedCode: # plot the CDF-CDF only for the selected data set, use True to plot for all\n",
    "            cdfx, cdfy = cdf(dfsel[code]['LogReturn']) # CDF of daily log returns\n",
    "            popt, pcov = curve_fit(func_normal_cdf, cdfx, cdfy) # fit normal's CDF to observed CDF\n",
    "            cdfy_fit = func_normal_cdf(cdfx, *popt) # CDF fit points\n",
    "            plt.plot(cdfy_fit,cdfy,c=color, marker='.', label=code, markersize=1, lw=1)\n",
    "    plt.title(\"Slope > 1 means : observed PDF > normal PDF\", fontsize=fontsize)\n",
    "    plt.xlabel(\"Normal fit CDF\", fontsize=fontsize)\n",
    "    plt.ylabel(\"Observed \" + which_period + \" log returns CDF\", fontsize=fontsize)\n",
    "    plt.plot([0,1],[0,1],\"k:\",lw=1,label=\"Slope=1\")\n",
    "    plt.legend(bbox_to_anchor=(0.02, .98), loc=2, borderaxespad=0., fontsize=fontsize)\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches([14, 4])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log return and Abs value of log return\n",
    "\n",
    "1. The number beside each symbol shows 1-step autocorrelation, for example, WMT (0.055). Which ticker's log return has negative autocorrelation ?\n",
    "2. When we switch from log return to the abs value of log return, how does the autocorrelation change ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# open/close code\n",
    "import matplotlib.pyplot as plt\n",
    "ylims=[-.45,.45]\n",
    "abs_ylims=[-.02,.45]\n",
    "fontsize=12\n",
    "marker='o'\n",
    "markersize=2\n",
    "\n",
    "# daily log return\n",
    "plt.subplot(211)\n",
    "for code,color in zip(yahooCodes,yahooColors):\n",
    "    s = df[code]['LogReturn']\n",
    "    autocorr = '%.3f' % s.autocorr()\n",
    "    plt.plot(s, c=color, marker=marker, ms=markersize, label = code + \" (\" + str(autocorr) + \")\", lw=0)\n",
    "plt.legend(bbox_to_anchor=(1.01, .98), loc=2, borderaxespad=0., fontsize=fontsize)\n",
    "plt.yscale('linear')\n",
    "plt.xlabel('Time [year]', fontsize=fontsize)\n",
    "plt.ylabel('Business Day Log Return', fontsize=fontsize)\n",
    "plt.xlim(xlims)\n",
    "plt.ylim(ylims)\n",
    "\n",
    "# absolute value of log return\n",
    "plt.subplot(212)\n",
    "for code,color in zip(yahooCodes,yahooColors):\n",
    "    s = np.absolute(df[code]['LogReturn'])\n",
    "    autocorr = '%.3f' % s.autocorr()\n",
    "    plt.plot(s, c=color, marker=marker, ms=markersize, label = code + \" (\" + str(autocorr) + \")\", lw=0)\n",
    "plt.legend(bbox_to_anchor=(1.01, .98), loc=2, borderaxespad=0., fontsize=fontsize)\n",
    "plt.yscale('linear')\n",
    "plt.xlabel('Time [year]', fontsize=fontsize)\n",
    "plt.ylabel('Absolute value of Log Return', fontsize=fontsize)\n",
    "plt.xlim(xlims)\n",
    "plt.ylim(abs_ylims)\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches([12, 10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autocorr of log return and abs log return\n",
    "\n",
    "These plots show autocorrelation vs time difference. \n",
    "\n",
    "1. Which daily log return has significantly nonzero autocorrelation ?\n",
    "2. Which abs daily log return has the highest and lowest autocorrelation after long time ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# open/close code\n",
    "# main parameters\n",
    "autocorr_len = 126 # check autocorrelation up to this number of business days\n",
    "xmargin_of_plot = 3\n",
    "autocorr_shifts = np.arange( 1 , autocorr_len + 1 )\n",
    "\n",
    "# imports and other parameters\n",
    "import matplotlib.pyplot as plt\n",
    "fontsize =14\n",
    "marker = 'o'\n",
    "markersize = 4   \n",
    "xlims = ( 1 - xmargin_of_plot, autocorr_len + xmargin_of_plot)\n",
    "ylims = ( -.2, .35 )\n",
    "axhline_width = 0.5\n",
    "\n",
    "# daily log return\n",
    "plt.subplot(121)\n",
    "for code,color in zip(yahooCodes,yahooColors):\n",
    "    s = df[code]['LogReturn']\n",
    "    autocorr = [ float( '%.3f' % s.autocorr(shift) ) for shift in autocorr_shifts ]\n",
    "    plt.plot(autocorr_shifts, autocorr, c=color, marker=marker, ms=markersize, label=code, lw=0)\n",
    "plt.legend(bbox_to_anchor=(.05, .98), loc=2, borderaxespad=0., fontsize=fontsize)\n",
    "plt.title(\"Autocorrelation of daily log return\", fontsize=fontsize)\n",
    "plt.yscale('linear')\n",
    "plt.xlabel('Shift [business days]', fontsize=fontsize)\n",
    "plt.ylabel('Autocorrelation with selected shift', fontsize=fontsize)\n",
    "plt.axhline(0, c='k', ls=':', lw=axhline_width)\n",
    "plt.axvline(0, c='k', ls=':', lw=axhline_width)\n",
    "plt.xlim(xlims)\n",
    "plt.ylim(ylims)\n",
    "\n",
    "# daily log return\n",
    "plt.subplot(122)\n",
    "for code,color in zip(yahooCodes,yahooColors):\n",
    "    s = np.absolute(df[code]['LogReturn'])\n",
    "    autocorr = [ float( '%.3f' % s.autocorr(shift) ) for shift in autocorr_shifts ]\n",
    "    plt.plot(autocorr_shifts, autocorr, c=color, marker=marker, ms=markersize, lw=0)\n",
    "plt.title(\"Autocorr. of the abs. value of the daily log return\", fontsize=fontsize)\n",
    "plt.yscale('linear')\n",
    "plt.xlabel('Shift [business days]', fontsize=fontsize)\n",
    "plt.axhline(0, c='k', ls=':', lw=axhline_width)\n",
    "plt.axvline(0, c='k', ls=':', lw=axhline_width)\n",
    "plt.xlim(xlims)\n",
    "plt.ylim(ylims)\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches([16, 8])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volume vs log Return\n",
    "\n",
    "1. What do you conclude from daily log return vs traded volume plotted for each day ?\n",
    "2. What do you conclude when points are binned by log return ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# open/close code\n",
    "# the portfolio.hu time series contain trading volume\n",
    "# we are assuming here that the data sets are already imported\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "pf_colors = ['red','limegreen','blue']\n",
    "markersize=2\n",
    "(xmin, xmax) = ( -0.55, 0.25 )\n",
    "xlims = (xmin, xmax)\n",
    "xbins = np.linspace(xmin, xmax, 100)\n",
    "axvline_width = 0.5\n",
    "marker='o'\n",
    "\n",
    "# set index to datetime, set closing value, log return, and traded volume\n",
    "for code in pf_codes:\n",
    "    df[code].index = pd.to_datetime( df[code]['Dátum'] )\n",
    "    df[code]['Close'] = df[code]['Záró ár']\n",
    "    df[code]['LogReturn']  = np.log(df[code]['Close']) -  np.log(df[code]['Close'].shift())\n",
    "    df[code]['Volume'] = df[code]['Forgalom (mFt)']\n",
    "\n",
    "# plot daily values\n",
    "plt.subplot(121)\n",
    "for code,color in zip(pf_codes, pf_colors):\n",
    "    if True: # plot all data sets\n",
    "    #if 'RICHTER' == code: # plot selected data set\n",
    "        plt.plot(df[code]['LogReturn'], df[code]['Volume'] / 1e+9, \n",
    "                 c=color, marker=marker, label=code, lw=0, markersize=markersize)\n",
    "plt.xlim(xlims)\n",
    "plt.title(\"Daily traded volume vs log return\")\n",
    "plt.legend(bbox_to_anchor=(.02, .02), loc=3, borderaxespad=0., fontsize=fontsize)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Daily log return', fontsize=fontsize)\n",
    "plt.ylabel('Traded volume (billion HUF)', fontsize=fontsize)\n",
    "plt.yticks([0.01,0.1,1,10,100],['0.01','0.1','1','10','100'])\n",
    "plt.axvline(0, c='k', ls=':', lw=axvline_width)\n",
    "\n",
    "plt.subplot(122)\n",
    "for code,color in zip(pf_codes, pf_colors):\n",
    "    if True: # plot all data sets\n",
    "    #if 'RICHTER' == code: # plot selected data set\n",
    "        groups = df[code].groupby(pd.cut(df[code]['LogReturn'], xbins))\n",
    "        plot_centers = ( xbins[:-1] + xbins[1:] ) / 2\n",
    "        plot_values = groups['Volume'].mean() / 1e+9\n",
    "        plt.plot(plot_centers, plot_values,\n",
    "                 c=color, marker=marker, label=code, lw=0, markersize=3*markersize)\n",
    "plt.xlim(xlims)\n",
    "plt.legend(bbox_to_anchor=(1.02, 1), loc=2, borderaxespad=0., fontsize=fontsize)\n",
    "plt.title(\"Traded volume is averaged in bins of log return\")\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Daily log return', fontsize=fontsize)\n",
    "plt.ylabel('Traded volume (billion HUF)', fontsize=fontsize)\n",
    "plt.yticks([3,10,30],['3','10','30'])\n",
    "plt.axvline(0, c='k', ls=':', lw=axvline_width)\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches([13, 5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volume vs Volatility of daily close\n",
    "\n",
    "1. Based on the below scatter plot what do you conclude for the relationship between daily log(volume) and log(volatility) ?\n",
    "2. Based on the roughly even distribution of the daily points in the plot what is your chance of having a high volume day ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# open/close code\n",
    "# imports, parameters\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "pf_colors = ['red','green','blue']\n",
    "markersize = 2\n",
    "\n",
    "def calculate_monthly_volatility_and_average_traded_volume(data):\n",
    "    '''For each month calculate the volatility of the daily close and the average daily traded volume.'''\n",
    "    monthly_data = pd.DataFrame(columns=['volatility','average_volume'])\n",
    "    dates = data.index    \n",
    "    yearly_dates = dates.groupby(dates.year)\n",
    "    for year in yearly_dates.keys():\n",
    "        monthly_dates = pd.DatetimeIndex(yearly_dates[year]).groupby(pd.DatetimeIndex(yearly_dates[year]).month)\n",
    "        for month in monthly_dates.keys():\n",
    "            date_all = monthly_dates[month]\n",
    "            date_first = min( date_all )\n",
    "            close_daily_all = [ data.loc[date]['Close'] for date in date_all ]\n",
    "            volume_daily_all = [ data.loc[date]['Volume'] for date in date_all ]\n",
    "            volatility = np.std( close_daily_all )\n",
    "            volume_daily_average = np.average( volume_daily_all )\n",
    "            monthly_data.loc[date_first] = [volatility, volume_daily_average]\n",
    "    return monthly_data\n",
    "\n",
    "# volume vs volatility\n",
    "monthly_data = dict()\n",
    "for code, color in zip(pf_codes, pf_colors):\n",
    "    if True: # all data sets\n",
    "    #if 'RICHTER' == code: # only selected data set\n",
    "        monthly_data[code] = calculate_monthly_volatility_and_average_traded_volume( df[code] )\n",
    "        plt.plot(monthly_data[code]['volatility'], monthly_data[code]['average_volume'] / 1e+9,\n",
    "                 c=color, marker=marker, label=code, lw=0, markersize=markersize)\n",
    "plt.legend(bbox_to_anchor=(.98, .02), loc=4, borderaxespad=0., fontsize=fontsize)\n",
    "plt.title(\"Monthly data: Average daily volume vs Volatility of daily close\")\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Volatility of daily close in a month (HUF)', fontsize=fontsize)\n",
    "plt.ylabel('Average daily volume (billion HUF)', fontsize=fontsize)\n",
    "plt.xticks([30,100,300,1000],['30','100','300','1000'])\n",
    "plt.yticks([1,3,10,30],['1','3','10','30'])\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches([8, 6])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skewness of log returns distribution \n",
    "\n",
    "1. What does the sum of the highest and the lowest value tell about a distribution ?\n",
    "2. Does the negative skew of SP500 mean that stock prices respond faster to negative news than to positive news ?\n",
    "\n",
    "| Name | Symbol and Calculation |\n",
    "|:-----|:------------|\n",
    "| Random variable | $X$ |\n",
    "| Mean | $\\mu = E\\left[ \\,X \\,\\right]$ |\n",
    "| Variance | ${\\displaystyle \\sigma^{\\,2} = E\\left[ \\, \\left( \\, X - \\mu \\, \\right)^{\\,2} \\, \\right] }$ |\n",
    "| Volatility = Std.dev. | $\\sigma$ |\n",
    "| Skewness | ${\\displaystyle E\\left[\\,\\left(\\frac{X-\\mu}{\\sigma}\\,\\right)^{\\,3} \\, \\right]}$|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# open/close code\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import datetime\n",
    "\n",
    "# select data sets to be analyzed, set their display names, set colors for plotting them\n",
    "fred_selected_codes = {'AAA10Y':'AAA10Y', 'GOLDPMGBD228NLBM':'GOLD', 'DEXJPUS':'JPYUSD', \n",
    "    'ICERATES1100USD1Y': 'US1YSW', 'SP500':'SP500', 'WILLRESIPR':'WILLSH'}\n",
    "fred_colors = ['black','blue','green','black','red','red']\n",
    "fred_markers = ['o','^','v','x','o','x']\n",
    "fred_fill = ['none','none','none','none','none','none']\n",
    "axhline_width = 0.5 \n",
    "markersize = 6\n",
    "markeredgewidth = 1\n",
    "display_len = 32 # display this number of points\n",
    "linthreshy = 0.002 # threshold for the simlog y scaling\n",
    "\n",
    "\n",
    "# read fred data sets again without the . lines, calculate log return\n",
    "for code in fred_selected_codes:\n",
    "    df[code] = pd.read_csv(data_dir + os.sep + code + \".\" + file_ext, na_values='.')\n",
    "    df[code]['LogReturn'] = np.log(df[code][code]) - np.log(df[code][code]).shift()\n",
    "\n",
    "\n",
    "# write skewness and plot differences\n",
    "print(\"Skew\\tLabel\\tLong Code of Data\")\n",
    "for code, color, marker, fill in zip(fred_selected_codes, fred_colors, fred_markers, fred_fill):\n",
    "    if True: # plot all data\n",
    "    #if code.startswith('AA'): # plot selected\n",
    "        log_returns = df[code]['LogReturn']\n",
    "        log_returns_num = log_returns[ (log_returns>-1e+6) & (log_returns<1e+6) ] # select numbers\n",
    "        sorted_log_returns = pd.Series.sort_values( log_returns_num ).tolist() # sort into ascending order\n",
    "        sum_reversed = np.add( sorted_log_returns, sorted_log_returns[::-1] ) # add list to itself reversed\n",
    "        sum_reversed = sum_reversed[:display_len:] # keep only the requested number of items from the start\n",
    "        display_name = fred_selected_codes[code]\n",
    "        print(\"%+.2f\\t%s\\t%s\" % (stats.skew(sorted_log_returns), display_name, code))\n",
    "        is_first = False\n",
    "        plt.plot(1 + np.arange(len(sum_reversed)) , sum_reversed,\n",
    "                 c=color, marker=marker, label=display_name, lw=0, fillstyle=fill, \n",
    "                 markersize=markersize, markeredgewidth=markeredgewidth)\n",
    "plt.title('Sum of $n^{th}$ lowest and $n^{th}$ highest daily log returns', fontsize=fontsize)\n",
    "plt.legend(bbox_to_anchor=(1.02, 1), loc=2, borderaxespad=0., fontsize=fontsize)\n",
    "plt.xscale('log')\n",
    "plt.yscale('symlog', linthreshy=linthreshy)\n",
    "plt.xlabel('Index of sorted daily log returns ($n$)', fontsize=fontsize)\n",
    "plt.xticks([1,3,10,30],['1','3','10','30'])\n",
    "plt.yticks([-0.01,-0.001,0,0.001,0.01,0.1],['$-\\,0.01$','$-\\,0.001$','','0.001','0.01','0.1'])\n",
    "plt.axhline(0, c='k', ls='--', lw=axhline_width)\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches([7, 5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autocorrelation vs Partial autocorrelation\n",
    "\n",
    "This section is optional material.\n",
    "\n",
    "The PAC at lag $\\,k\\,$ is the correlation between $\\,X(t)\\,$ and $\\,X(t-k)\\,$ after removing the effects of $\\,X(t-1)\\,$, ... , $\\,X(t-k+1)\\,$.  \n",
    "\n",
    "One of the algorithms calculates ordinary least squares (OLS) with regressand $\\,X(t)\\,$ and the lagged values as regressors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# open/close code\n",
    "import pandas as pd\n",
    "from statsmodels.tsa import stattools\n",
    "nlags = 10 # number of earlier values used for the PACF\n",
    "pf_markers = ['o','x','^']\n",
    "markersize = 6\n",
    "fill = 'none'\n",
    "axline_width = 0.5\n",
    "xticks = [1,2,4,6,8,10]\n",
    "\n",
    "# calculate ACF and PACF, plot ACF\n",
    "plt.subplot(121)\n",
    "data_pacf = dict()\n",
    "for code, color, marker in zip(pf_codes, pf_colors, pf_markers):\n",
    "    log_returns = pd.Series( data = np.log(df[code]['Záró ár']) - np.log(df[code]['Záró ár'].shift()) )\n",
    "    log_returns.dropna(inplace=True)\n",
    "    data_acf = stattools.acf(log_returns, nlags=nlags)\n",
    "    data_pacf[code] = stattools.pacf(log_returns, nlags=nlags)\n",
    "    plt.plot( np.arange(1,nlags+1), data_acf[1:], c=color, marker=marker,\n",
    "              label=code, lw=0, fillstyle=fill, markersize=markersize )\n",
    "plt.xlabel('$k\\,$ (lag)', fontsize=fontsize)\n",
    "plt.title('Autocorrelation at lag $k$', fontsize=fontsize)\n",
    "plt.xticks(xticks)\n",
    "plt.axhline(0, c='k', ls=':', lw=axline_width)\n",
    "plt.axvline(1, c='k', ls=':', lw=axline_width)\n",
    "\n",
    "# plot PACF\n",
    "plt.subplot(122)\n",
    "for code, color, marker in zip(pf_codes, pf_colors, pf_markers):\n",
    "    plt.plot( np.arange(1,nlags+1), data_pacf[code][1:], c=color, marker=marker,\n",
    "              label=code, lw=0, fillstyle=fill, markersize=markersize )\n",
    "plt.legend(bbox_to_anchor=(1.03, 1), loc=2, borderaxespad=0., fontsize=fontsize)\n",
    "plt.xlabel('$k\\,$ (lag)', fontsize=fontsize)\n",
    "plt.title('Partial autocorrelation at lag $k$', fontsize=fontsize)\n",
    "plt.xticks(xticks)\n",
    "plt.axhline(0, c='k', ls=':', lw=axline_width)\n",
    "plt.axvline(1, c='k', ls=':', lw=axline_width)\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches([10, 6])\n",
    "plt.show()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "304.313px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
